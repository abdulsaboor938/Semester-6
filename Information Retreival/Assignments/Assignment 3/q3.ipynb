{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a web crawling program in the language of your choice. Your program must meet the\n",
    "# criteria described below. Also, write a report of up to half a page describing your crawling\n",
    "# approach. What are your crawler's strengths and vulnerabilities? Would you use this program in a\n",
    "# production setting? What problems would it face, and how could it be improved? While you don't\n",
    "# need to go \"above and beyond\" the criteria below, you are encouraged to think about what that\n",
    "# might mean.\n",
    "# Program Specification\n",
    "# 1. Start at the URL http://www.mit.edu and visit only web pages in the mit.edu domain.\n",
    "# 2. Stop once you have visited 100 HTML pages.\n",
    "# 3. Detect whether a page you visit is an HTML document, a PDF, or something else using the\n",
    "# appropriate Content-Type HTTP header.\n",
    "# 4. Detect all outgoing links on each HTML page you visit, and follow only links to pages\n",
    "# you have not yet visited. This will require you to convert some links to a canonical form,\n",
    "# e.g. http://somepage.com/my_page.html# should be converted to\n",
    "# http://somepage.com/my_page.html.\n",
    "# 5. For every web page you visit, write its canonical URL and the canonical URLs of each\n",
    "# outgoing link to an HTML or PDF file, separated by a single space, to a plain text output\n",
    "# file, with one line per visited page.\n",
    "# 6. Put some thought into the pages you decide to visit, and the order in which you visit them.\n",
    "# Is there any way links on web pages could cause your crawler to misbehave? Remember\n",
    "# that a crawler on the open web will face many novice and malicious web developers.\n",
    "# 7. Your crawler must visit at most one page per five seconds. Under no circumstances, even\n",
    "# during development and testing, should your crawler visit pages more frequently. This is\n",
    "# necessary in order to be respectful of the limited resources of the web servers you are\n",
    "# visiting. (Feel free during development to reduce the total number of pages you visit if this\n",
    "# is slowing you down.)\n",
    "# 8. Your crawler must respect robots.txt (https://web.mit.edu/robots.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import urljoin\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from collections import deque\n",
    "from urllib.parse import urldefrag\n",
    "from urllib.parse import urlsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "visited = set()\n",
    "queue = deque()\n",
    "count = 0\n",
    "domain = 'mit.edu'\n",
    "rp = RobotFileParser()\n",
    "rp.set_url('http://www.mit.edu/robots.txt')\n",
    "rp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if the url is valid\n",
    "def is_valid(url):\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        if parsed.scheme not in set([\"http\", \"https\"]):\n",
    "            return False\n",
    "        if not re.match(r'.*\\.mit\\.edu$', parsed.netloc):\n",
    "            return False\n",
    "        if not rp.can_fetch(\"*\", url):\n",
    "            return False\n",
    "        if parsed.query:\n",
    "            return False\n",
    "        if parsed.fragment:\n",
    "            return False\n",
    "        return True\n",
    "    except TypeError:\n",
    "        print (\"TypeError for \", parsed)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the canonical url\n",
    "def get_canonical_url(url):\n",
    "    url = urldefrag(url)[0]\n",
    "    url = urlsplit(url)\n",
    "    url = url._replace(path = re.sub(r'/$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.html$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.htm$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.php$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.asp$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.jsp$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.cgi$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.pl$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.xhtml$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.htm$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.shtml$', '', url.path))\n",
    "    url = url._replace(path = re.sub(r'index\\.xhtm$', '', url.path))\n",
    "    return url.geturl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the links from the url\n",
    "def get_links(url):\n",
    "    global count\n",
    "    global visited\n",
    "    global queue\n",
    "    global domain\n",
    "    global rp\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        content_type = response.headers['content-type']\n",
    "        if 'text/html' in content_type:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            for link in soup.find_all('a'):\n",
    "                link = link.get('href')\n",
    "                if link is not None:\n",
    "                    link = get_canonical_url(link)\n",
    "                    if is_valid(link):\n",
    "                        if link not in visited:\n",
    "                            if domain in link:\n",
    "                                visited.add(link)\n",
    "                                queue.append(link)\n",
    "                                count += 1\n",
    "                                print (count, link)\n",
    "        elif 'application/pdf' in content_type:\n",
    "            print (count, url)\n",
    "        else:\n",
    "            print (count, url)\n",
    "    except:\n",
    "        print (count, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 http://www.mit.edu\n",
      "2 http://news.mit.edu\n",
      "3 https://president.mit.edu/about-mit-president-sally-kornbluth\n",
      "4 https://inauguration.mit.edu/street-fair\n",
      "5 http://inauguration.mit.edu/we-are-the-forest\n",
      "6 https://inauguration.mit.edu/academic-symposium\n",
      "7 https://inauguration.mit.edu/inauguration-ceremony\n",
      "8 https://inauguration.mit.edu/inauguration-concert\n",
      "9 http://inauguration.mit.edu\n",
      "10 http://news.mit.edu/news-clip/national-public-radio-npr-43\n",
      "11 http://news.mit.edu/2023/speedy-robo-gripper-reflexively-organizes-spaces-0427\n",
      "12 http://news.mit.edu/2023/amelia-dogan-driving-toward-data-justice-0426\n",
      "13 http://whereis.mit.edu\n",
      "14 http://calendar.mit.edu\n",
      "15 http://careers.mit.edu\n",
      "16 http://socialmediahub.mit.edu\n",
      "17 http://web.mit.edu\n",
      "18 http://web.mit.edu/education\n",
      "19 http://web.mit.edu/research\n",
      "20 http://web.mit.edu/innovation\n",
      "21 http://web.mit.edu/admissions-aid\n",
      "22 http://web.mit.edu/campus-life\n",
      "23 http://web.mit.edu/alumni\n",
      "24 http://web.mit.edu/about\n",
      "25 http://web.mit.edu/search\n",
      "26 http://web.mit.edu/feedback\n",
      "27 http://web.mit.edu/mit-daily-weekly\n",
      "28 http://web.mit.edu/subscribe\n",
      "29 https://www-science-org.libproxy.mit.edu/doi/10.1126/science.adg5619\n",
      "30 http://comms.mit.edu\n",
      "31 http://web.mit.edu/building-a-better-world\n",
      "32 http://web.mit.edu/visitmit\n",
      "33 http://web.mit.edu/people.html\n",
      "34 http://web.mit.edu/contact\n",
      "35 http://web.mit.edu/privacy\n",
      "36 http://web.mit.edu/accessibility\n",
      "37 https://news.mit.edu/2022/sally-kornbluth-named-MIT-president-1020\n",
      "38 https://news.mit.edu/2022/kornbluth-remarks-community-1020\n",
      "39 https://web.mit.edu/accessibility\n",
      "39 https://inauguration.mit.edu/street-fair\n",
      "40 http://mta.mit.edu/person/fred-harris\n",
      "41 http://mta.mit.edu/music/performance/mit-wind-ensemble\n",
      "42 http://mta.mit.edu/music/performance/festival-jazz-ensemble\n",
      "43 http://mta.mit.edu/music/performance/mit-vocal-jazz-ensemble\n",
      "44 http://mta.mit.edu\n",
      "45 https://inauguration.mit.edu/privacy-policy\n",
      "46 https://inauguration.mit.edu/site-accessibility\n",
      "47 https://institute-events.mit.edu\n",
      "47 https://inauguration.mit.edu/academic-symposium\n",
      "47 https://inauguration.mit.edu/inauguration-ceremony\n",
      "47 https://inauguration.mit.edu/inauguration-concert\n",
      "48 https://inauguration.mit.edu/we-are-the-forest\n",
      "49 https://inauguration.mit.edu/webcasts\n",
      "50 http://inauguration.mit.edu/academic-symposium\n",
      "51 https://news.mit.edu\n",
      "52 http://inauguration.mit.edu/inauguration-ceremony\n",
      "53 http://inauguration.mit.edu/schedule\n",
      "54 https://news.mit.edu/2023/curiosity-unbounded-podcast-desiree-plata-0419\n",
      "55 https://biomimetics.mit.edu/research/reflexive-control\n",
      "56 https://news.mit.edu/2022/3-questions-how-mit-mini-cheetah-learns-run-fast-0317\n",
      "57 https://meche.mit.edu/people/faculty/SANGBAE@MIT.EDU\n",
      "58 https://biomimetics.mit.edu\n",
      "59 https://meche.mit.edu\n",
      "60 https://engineering.mit.edu\n",
      "61 https://urop.mit.edu\n",
      "62 https://superurop.mit.edu\n",
      "63 http://asianamerican.mit.edu\n",
      "64 https://dataplusfeminism.mit.edu\n",
      "65 https://dusp.mit.edu\n",
      "66 https://shass.mit.edu/undergraduate/interdisciplinary/majors/american\n",
      "67 https://sap.mit.edu\n",
      "68 https://shass.mit.edu\n",
      "69 http://web.mit.edu/campus-map/pdf/mit-accessibility-color-current.pdf\n",
      "70 https://calendar.mit.edu/event/future_compute_6200\n",
      "71 https://calendar.mit.edu/event/inauguration_day\n",
      "72 https://calendar.mit.edu/event/emtech_digital_4186\n",
      "73 https://calendar.mit.edu/event/getting_to_diversity_what_works_and_what_doesnt_fireside_chat_with_frank_dobbin_ph_d_and_alexandra_kalev_ph_d\n",
      "74 https://calendar.mit.edu/event/science_surfaces\n",
      "75 https://calendar.mit.edu/building_76\n",
      "76 https://calendar.mit.edu/event/south_asia_and_the_institute_transformative_connections_2149\n",
      "77 https://calendar.mit.edu/building_14\n",
      "78 https://calendar.mit.edu/event/sp_regalia_rental_1824\n",
      "79 https://calendar.mit.edu/event/mit250_-_ten_minutes_of_daily_reflection_4924\n",
      "80 https://calendar.mit.edu/event/mit_open_ballroom_dance_competition_9498\n",
      "81 https://calendar.mit.edu/building_w33\n",
      "82 https://calendar.mit.edu/event/warehouse_live_music_brunch_1765\n",
      "83 https://calendar.mit.edu/event/brunch\n",
      "84 https://calendar.mit.edu/building_nw35\n",
      "85 https://calendar.mit.edu/event/mentor_program_2023_open_application\n",
      "86 https://calendar.mit.edu/event/mit250_-_americas_-_ten_minutes_of_daily_mindfulness\n",
      "87 https://calendar.mit.edu/calendar\n",
      "88 https://calendar.mit.edu/event/memorial_day\n",
      "89 https://calendar.mit.edu/event/independence_day\n",
      "90 https://calendar.mit.edu/event/mit-merck_lectures_in_organic_chemistry_Tom_Maimone_UC_Berkeley_merck\n",
      "91 https://calendar.mit.edu/event/lce_tea_talk\n",
      "92 https://calendar.mit.edu/event/community-dinner\n",
      "93 https://calendar.mit.edu/building_w11\n",
      "94 https://calendar.mit.edu/event/screening_discussion_nuclear_now_with_director_oliver_stone_and_co-writer_joshua_s_goldstein\n",
      "95 https://calendar.mit.edu/event/buchi_lectures_in_organic_chemistry_Veronique_Gouverneur_Oxford\n",
      "96 https://calendar.mit.edu/event/2023_mit_ai_and_autonomy_conference\n",
      "97 https://calendar.mit.edu/browse/places\n",
      "98 https://calendar.mit.edu/browse/departments\n",
      "99 https://calendar.mit.edu/browse/groups\n",
      "100 https://kb.mit.edu/confluence/display/istcontrib/MIT+Events+Calendar+-+Register+a+Student+Group%2C+Organization+or+DLC\n",
      "101 http://kb.mit.edu/confluence/display/istcontrib/MIT+Events+Calendar+Landing+Page\n",
      "102 http://web.mit.edu/ist-train/EventCalendar\n",
      "103 http://kb.mit.edu/confluence/x/_xFhCQ\n",
      "104 http://web.mit.edu/registrar/calendar/\n",
      "105 https://institute-events.mit.edu/visit\n",
      "106 https://institute-events.mit.edu/visit/tours\n",
      "107 http://institute-events.mit.edu/information-center\n",
      "108 http://institute-events.mit.edu/visit/directions\n",
      "109 https://accessibility.mit.edu\n",
      "110 http://institute-events.mit.edu\n"
     ]
    }
   ],
   "source": [
    "global count\n",
    "global visited\n",
    "global queue\n",
    "global domain\n",
    "global rp\n",
    "url = 'http://www.mit.edu'\n",
    "visited.add(url)\n",
    "queue.append(url)\n",
    "count += 1\n",
    "print (count, url)\n",
    "while count < 100 and queue:\n",
    "    url = queue.popleft()\n",
    "    get_links(url)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the visited urls to the file\n",
    "with open('q3_visited.txt', 'w') as f:\n",
    "    for url in visited:\n",
    "        f.write(\"%s\\n\" % url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
